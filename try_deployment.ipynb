{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T11:36:01.077609Z",
     "start_time": "2025-01-14T11:35:55.768859Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe5a2866866ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "First I need a model to deploy\n",
    "\n",
    "import os\n",
    "from typing import Any, Optional\n",
    "\n",
    "# from custom_code import iris_classes\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "flower_classes = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "\n",
    "\n",
    "def iris_classes(preds):\n",
    "    return [flower_classes[x] for x in preds]\n",
    "\n",
    "\n",
    "class CustomPredict(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"Custom pyfunc class used to create customized mlflow models\"\"\"\n",
    "\n",
    "    def load_context(self, context):\n",
    "        self.model = mlflow.sklearn.load_model(context.artifacts[\"custom_model\"])\n",
    "\n",
    "    def predict(self, context, model_input, params: Optional[dict[str, Any]] = None):\n",
    "        prediction = self.model.predict(model_input)\n",
    "        return iris_classes(prediction)\n",
    "\n",
    "\n",
    "X, y = load_iris(return_X_y=True, as_frame=True)\n",
    "params = {\"C\": 1.0, \"random_state\": 42}\n",
    "classifier = LogisticRegression(**params).fit(X, y)\n",
    "\n",
    "predictions = classifier.predict(X)\n",
    "signature = infer_signature(X, predictions)\n",
    "\n",
    "with mlflow.start_run(run_name=\"test_pyfunc\") as run:\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=classifier, artifact_path=\"model\", signature=signature\n",
    "    )\n",
    "\n",
    "    # start a child run to create custom imagine model\n",
    "    with mlflow.start_run(run_name=\"test_custom_model\", nested=True):\n",
    "        print(f\"Pyfunc run ID: {run.info.run_id}\")\n",
    "        # log a custom model\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"artifacts\",\n",
    "            code_paths=[os.getcwd()],\n",
    "            artifacts={\"custom_model\": model_info.model_uri},\n",
    "            python_model=CustomPredict(),\n",
    "            signature=signature,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dbb01925b9e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output specifications examples\n",
    "# Compatible with OpenAI spec\n",
    "input = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is MLflow?\"}],\n",
    "    \"max_tokens\": 25,\n",
    "}\n",
    "output = {\n",
    "    \"choices\": [\n",
    "        {\n",
    "            \"index\": 0,\n",
    "            \"message\": {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"MLflow is an open-source platform for machine learning (ML) and artificial intelligence (AI). It's designed to manage,\",\n",
    "            },\n",
    "            \"finish_reason\": \"stop\",\n",
    "        }\n",
    "    ],\n",
    "    \"model\": \"llama3.2:1b\",\n",
    "    \"object\": \"chat.completion\",\n",
    "    \"created\": 1729190863,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398ca83bef37e080",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T12:49:31.211553Z",
     "start_time": "2025-01-14T12:49:30.875527Z"
    }
   },
   "outputs": [],
   "source": [
    "# simple chat model\n",
    "\n",
    "from mlflow.pyfunc import ChatModel\n",
    "from mlflow.types.llm import ChatMessage, ChatCompletionResponse, ChatChoice, ChatParams\n",
    "\n",
    "\n",
    "class MySimpleChatModel(ChatModel):\n",
    "    def __init__(self):\n",
    "        self.model_name = \"lucag-first_chat_model-v1\"\n",
    "        # self.client = None\n",
    "        \n",
    "    def load_context(self, context):\n",
    "        pass\n",
    "    \n",
    "    def predict(\n",
    "        self, context, messages: list[ChatMessage], params: ChatParams\n",
    "    ) -> ChatCompletionResponse:\n",
    "        return ChatCompletionResponse(\n",
    "            object=\"chat.completion\",\n",
    "            model=self.model_name,\n",
    "            # created=1729190863,\n",
    "            choices=[\n",
    "                ChatChoice(\n",
    "                    index=0,\n",
    "                    message=ChatMessage(\n",
    "                        role=\"assistant\",\n",
    "                        content=\"Beautiful day today!\",\n",
    "                    ),\n",
    "                    finish_reason=\"stop\",\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "    \n",
    "my_model = MySimpleChatModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f1d7ab836e0dd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T12:49:42.897741Z",
     "start_time": "2025-01-14T12:49:42.886641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionResponse(choices=[ChatChoice(message=ChatMessage(role='assistant', content='Beautiful day today!', refusal=None, name=None, tool_calls=None, tool_call_id=None), index=0, finish_reason='stop', logprobs=None)], usage=None, id=None, model='lucag-first_chat_model', object='chat.completion', created=1736858982, custom_outputs=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.predict(None, [ChatMessage(role=\"user\", content=\"Hello!\")], ChatParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7beb0773c97e526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T12:56:59.270812Z",
     "start_time": "2025-01-14T12:56:48.934691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/14 13:56:49 INFO mlflow.tracking.fluent: Experiment with name 'chatmodel-test' does not exist. Creating a new experiment.\n",
      "2025/01/14 13:56:49 INFO mlflow.pyfunc: Predicting on input example to validate output\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"chatmodel-test\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        \"lucag-first_chat_model\",\n",
    "        python_model=my_model,\n",
    "        input_example={\n",
    "          \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}],  \n",
    "        },\n",
    "    )"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# result = mlflow.register_model(\n",
    "#     \"runs:/d16076a3ec534311817565e6527539c0/sklearn-model\", \"sk-learn-random-forest-reg\"\n",
    "# )"
   ],
   "id": "b83884953218d0ed"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bb815b7192d8a10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T12:57:52.043463Z",
     "start_time": "2025-01-14T12:57:52.034355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__firstlineno__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_artifact_path', '_env_vars', '_flavors', '_metadata', '_mlflow_version', '_model_uri', '_model_uuid', '_registered_model_version', '_run_id', '_saved_input_example_info', '_signature', '_signature_dict', '_utc_time_created', 'artifact_path', 'env_vars', 'flavors', 'metadata', 'mlflow_version', 'model_uri', 'model_uuid', 'registered_model_version', 'run_id', 'saved_input_example_info', 'signature', 'signature_dict', 'utc_time_created']\n",
      "runs:/b9bac7ff6622442ca0863fd2563ab383/lucag-first_chat_model\n"
     ]
    }
   ],
   "source": [
    "print(dir(model_info))\n",
    "print(model_info.model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41c2b52aa3f6191f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T12:58:57.742326Z",
     "start_time": "2025-01-14T12:58:57.444871Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cf9cd802de7e473",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T13:00:48.256250Z",
     "start_time": "2025-01-14T13:00:48.237451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_PyFuncModel__model_impl', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__firstlineno__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_model_impl', '_model_meta', '_predict', '_predict_fn', '_predict_stream', '_predict_stream_fn', '_try_get_or_generate_prediction_context', 'get_raw_model', 'loader_module', 'metadata', 'model_config', 'predict', 'predict_stream', 'unwrap_python_model']\n",
      "artifact_path: lucag-first_chat_model\n",
      "flavors:\n",
      "  python_function:\n",
      "    cloudpickle_version: 3.1.0\n",
      "    code: null\n",
      "    env:\n",
      "      conda: conda.yaml\n",
      "      virtualenv: python_env.yaml\n",
      "    loader_module: mlflow.pyfunc.loaders.chat_model\n",
      "    python_model: python_model.pkl\n",
      "    python_version: 3.13.0\n",
      "    streamable: true\n",
      "mlflow_version: 2.19.0\n",
      "model_size_bytes: 1983\n",
      "model_uuid: 93fa39d846214c5294d328f2f22c1fb7\n",
      "run_id: b9bac7ff6622442ca0863fd2563ab383\n",
      "saved_input_example_info:\n",
      "  artifact_path: input_example.json\n",
      "  serving_input_path: serving_input_example.json\n",
      "  type: json_object\n",
      "signature:\n",
      "  inputs: '[{\"type\": \"array\", \"items\": {\"type\": \"object\", \"properties\": {\"content\":\n",
      "    {\"type\": \"string\", \"required\": false}, \"name\": {\"type\": \"string\", \"required\":\n",
      "    false}, \"refusal\": {\"type\": \"string\", \"required\": false}, \"role\": {\"type\": \"string\",\n",
      "    \"required\": true}, \"tool_call_id\": {\"type\": \"string\", \"required\": false}, \"tool_calls\":\n",
      "    {\"type\": \"array\", \"items\": {\"type\": \"object\", \"properties\": {\"function\": {\"type\":\n",
      "    \"object\", \"properties\": {\"arguments\": {\"type\": \"string\", \"required\": true}, \"name\":\n",
      "    {\"type\": \"string\", \"required\": true}}, \"required\": true}, \"id\": {\"type\": \"string\",\n",
      "    \"required\": true}, \"type\": {\"type\": \"string\", \"required\": true}}}, \"required\":\n",
      "    false}}}, \"name\": \"messages\", \"required\": true}, {\"type\": \"double\", \"name\": \"temperature\",\n",
      "    \"required\": false}, {\"type\": \"long\", \"name\": \"max_tokens\", \"required\": false},\n",
      "    {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"name\": \"stop\", \"required\": false},\n",
      "    {\"type\": \"long\", \"name\": \"n\", \"required\": false}, {\"type\": \"boolean\", \"name\":\n",
      "    \"stream\", \"required\": false}, {\"type\": \"double\", \"name\": \"top_p\", \"required\":\n",
      "    false}, {\"type\": \"long\", \"name\": \"top_k\", \"required\": false}, {\"type\": \"double\",\n",
      "    \"name\": \"frequency_penalty\", \"required\": false}, {\"type\": \"double\", \"name\": \"presence_penalty\",\n",
      "    \"required\": false}, {\"type\": \"array\", \"items\": {\"type\": \"object\", \"properties\":\n",
      "    {\"function\": {\"type\": \"object\", \"properties\": {\"description\": {\"type\": \"string\",\n",
      "    \"required\": false}, \"name\": {\"type\": \"string\", \"required\": true}, \"parameters\":\n",
      "    {\"type\": \"object\", \"properties\": {\"additionalProperties\": {\"type\": \"boolean\",\n",
      "    \"required\": false}, \"properties\": {\"type\": \"map\", \"values\": {\"type\": \"object\",\n",
      "    \"properties\": {\"description\": {\"type\": \"string\", \"required\": false}, \"enum\": {\"type\":\n",
      "    \"array\", \"items\": {\"type\": \"string\"}, \"required\": false}, \"items\": {\"type\": \"object\",\n",
      "    \"properties\": {\"type\": {\"type\": \"string\", \"required\": true}}, \"required\": false},\n",
      "    \"type\": {\"type\": \"string\", \"required\": true}}}, \"required\": true}, \"required\":\n",
      "    {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"required\": false}, \"type\": {\"type\":\n",
      "    \"string\", \"required\": false}}, \"required\": true}, \"strict\": {\"type\": \"boolean\",\n",
      "    \"required\": false}}, \"required\": false}, \"type\": {\"type\": \"string\", \"required\":\n",
      "    true}}}, \"name\": \"tools\", \"required\": false}, {\"type\": \"map\", \"values\": {\"type\":\n",
      "    \"any\"}, \"name\": \"custom_inputs\", \"required\": false}]'\n",
      "  outputs: '[{\"type\": \"string\", \"name\": \"id\", \"required\": true}, {\"type\": \"string\",\n",
      "    \"name\": \"object\", \"required\": true}, {\"type\": \"long\", \"name\": \"created\", \"required\":\n",
      "    true}, {\"type\": \"string\", \"name\": \"model\", \"required\": true}, {\"type\": \"array\",\n",
      "    \"items\": {\"type\": \"object\", \"properties\": {\"finish_reason\": {\"type\": \"string\",\n",
      "    \"required\": true}, \"index\": {\"type\": \"long\", \"required\": true}, \"message\": {\"type\":\n",
      "    \"object\", \"properties\": {\"content\": {\"type\": \"string\", \"required\": false}, \"name\":\n",
      "    {\"type\": \"string\", \"required\": false}, \"refusal\": {\"type\": \"string\", \"required\":\n",
      "    false}, \"role\": {\"type\": \"string\", \"required\": true}, \"tool_call_id\": {\"type\":\n",
      "    \"string\", \"required\": false}, \"tool_calls\": {\"type\": \"array\", \"items\": {\"type\":\n",
      "    \"object\", \"properties\": {\"function\": {\"type\": \"object\", \"properties\": {\"arguments\":\n",
      "    {\"type\": \"string\", \"required\": true}, \"name\": {\"type\": \"string\", \"required\": true}},\n",
      "    \"required\": true}, \"id\": {\"type\": \"string\", \"required\": true}, \"type\": {\"type\":\n",
      "    \"string\", \"required\": true}}}, \"required\": false}}, \"required\": true}}}, \"name\":\n",
      "    \"choices\", \"required\": true}, {\"type\": \"object\", \"properties\": {\"completion_tokens\":\n",
      "    {\"type\": \"long\", \"required\": true}, \"prompt_tokens\": {\"type\": \"long\", \"required\":\n",
      "    true}, \"total_tokens\": {\"type\": \"long\", \"required\": true}}, \"name\": \"usage\", \"required\":\n",
      "    false}, {\"type\": \"map\", \"values\": {\"type\": \"any\"}, \"name\": \"custom_outputs\", \"required\":\n",
      "    false}]'\n",
      "  params: null\n",
      "utc_time_created: '2025-01-14 12:56:49.806393'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dir(loaded_model))\n",
    "print(loaded_model.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83531c9db3840002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T13:02:37.749928Z",
     "start_time": "2025-01-14T13:02:37.741126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'message': {'role': 'assistant', 'content': 'Beautiful day today!'}, 'index': 0, 'finish_reason': 'stop'}], 'model': 'lucag-first_chat_model', 'object': 'chat.completion', 'created': 1736859757}\n"
     ]
    }
   ],
   "source": [
    "result = loaded_model.predict(\n",
    "    data={\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"What is MLflow?\"}],\n",
    "        \"max_tokens\": 25,\n",
    "    }\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca8c73903867eb",
   "metadata": {},
   "source": [
    "Ok, we have a model now. Let's see how to deploy it.\n",
    "\n",
    "Let's try this:\n",
    "\n",
    "`mlflow models serve -m runs:/<run_id>/model -p 5000`"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Serv locally with \n",
    "```\n",
    "mlflow models serve -m runs:/b9bac7ff6622442ca0863fd2563ab383/lucag-first_chat_model -p 5000 --env-manager=local\n",
    "```"
   ],
   "id": "e7b5702d1ced234c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Test in PowerShell with:\n",
    "\n",
    "```\n",
    "curl http://127.0.0.1:5000/invocations -Method Post -ContentType application/json -Body '{\"inputs\": {\"messages\": [{\"role\": \"user\", \"content\": \"Tell a joke!\"}]}}'\n",
    "```"
   ],
   "id": "48d2e2976044c5dc"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9a5e09d15f0f15f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T14:18:51.190539Z",
     "start_time": "2025-01-14T14:18:49.166853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': {'choices': [{'message': {'role': 'assistant', 'content': 'Beautiful day today!'}, 'index': 0, 'finish_reason': 'stop'}], 'model': 'lucag-first_chat_model', 'object': 'chat.completion', 'created': 1736864331}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "payload = json.dumps(\n",
    "    {\n",
    "        \"inputs\": {\"messages\": [{\"role\": \"user\", \"content\": \"Tell a joke!\"}]},\n",
    "        \"params\": {\n",
    "            \"temperature\": 0.5,\n",
    "            \"max_tokens\": 20,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "response = requests.post(\n",
    "    url=f\"http://localhost:5000/invocations\",\n",
    "    data=payload,\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    ")\n",
    "print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-playground-3.13",
   "language": "python",
   "name": "mlflow-playground-3.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
